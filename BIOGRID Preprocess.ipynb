{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03191fb-d2a3-4e80-9a1b-712a325e8358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import itertools as it\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48232a50-ae73-4059-a9a9-1428404e23a8",
   "metadata": {},
   "source": [
    "## Initial data preprocessing (renaming, only humans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce18741c-e8b9-490a-b729-82ef35ea5c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./BIOGRID-ALL-4.4.222.trunc.tsv\", sep=\"\\t\")\n",
    "df.columns = [\"Symbol A\", \"Symbol B\", \"Synonym A\", \"Synonym B\", \"Uniprot A\", \"Uniprot B\", \"Organism A\", \"Organism B\"]\n",
    "\n",
    "df = df[(df[\"Organism A\"] == \"Homo sapiens\") & (df[\"Organism B\"] == \"Homo sapiens\")].reset_index(drop=True)\n",
    "df = df.drop(columns=[\"Organism A\", \"Organism B\"])\n",
    "\n",
    "df[\"Uniprot A\"] = \"uniprot:\" + df[\"Uniprot A\"].astype(str)\n",
    "df[\"Uniprot B\"] = \"uniprot:\" + df[\"Uniprot B\"].astype(str)\n",
    "\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8165cf98-381e-4e7f-af72-d4836c6a2f27",
   "metadata": {},
   "source": [
    "### Handle unmapped UniProt IDs\n",
    "* Drop the ones that couldn't be recovered\n",
    "* Requires using the UniProt mapping web tool. Could implement using the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8b9f9b-c9fc-4673-b90e-405c241fb1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unmapped uniprot IDs and export them to map them using UniProt's web tool\n",
    "pd.DataFrame(list(set(pd.concat([\n",
    "    df[df[\"Uniprot A\"] == \"uniprot:-\"][\"Symbol A\"],\n",
    "    df[df[\"Uniprot B\"] == \"uniprot:-\"][\"Symbol B\"]\n",
    "])))).to_csv(\"./no-uniprot.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dbf957-b2b1-46c4-aceb-575f76f9b81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After recovering IDs and collecting the right columns from UniProt's tool\n",
    "# Required columns: [\"From\", \"Entry\", Organism\"]\n",
    "up_map = pd.read_csv(\"./no-uniprot_mapping.tsv\", sep=\"\\t\")\n",
    "up_map = up_map[up_map[\"Organism\"] == \"Homo sapiens (Human)\"]\n",
    "up_map = up_map[[\"From\", \"Entry\"]].drop_duplicates(subset=[\"From\"])\n",
    "up_map[\"Entry\"] = \"uniprot:\" + up_map[\"Entry\"].astype(str)\n",
    "up_map.columns = [\"Symbol\", \"Uniprot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f764a015-2e77-4f92-81e2-18a42974efc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover unmapped UniProt IDs. Separated by A and B\n",
    "noup_a = df[df[\"Uniprot A\"] == \"uniprot:-\"].copy().reset_index(drop=True)\n",
    "noup_a[\"Uniprot A\"] = noup_a.merge(up_map, left_on=[\"Symbol A\"], right_on=\"Symbol\", how=\"left\")[\"Uniprot\"]\n",
    "df = df[df[\"Uniprot A\"] != \"uniprot:-\"]\n",
    "df = pd.concat([df, noup_a])\n",
    "\n",
    "noup_b = df[df[\"Uniprot B\"] == \"uniprot:-\"].copy().reset_index(drop=True)\n",
    "noup_b[\"Uniprot B\"] = noup_b.merge(up_map, left_on=[\"Symbol B\"], right_on=\"Symbol\", how=\"left\")[\"Uniprot\"]\n",
    "df = df[df[\"Uniprot B\"] != \"uniprot:-\"]\n",
    "df = pd.concat([df, noup_b])\n",
    "\n",
    "df = df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d84bc3-004d-4ce4-b25a-003c2ecd5035",
   "metadata": {},
   "source": [
    "## Export edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176b99e7-f1bd-406a-9b1a-ac68df8d813a",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_df = df[[\"Uniprot A\", \"Uniprot B\"]].rename(columns={\"Uniprot A\": \"source\", \"Uniprot B\": \"target\"})\n",
    "\n",
    "G = nx.from_pandas_edgelist(edges_df, source=\"source\", target=\"target\", create_using=nx.Graph())\n",
    "\n",
    "with open(\"BIOGRID_edges.pkl\", \"wb\") as p:\n",
    "    pickle.dump(edges_df, p)\n",
    "\n",
    "with open(\"BIOGRID_graph.pkl\", \"wb\") as p:\n",
    "    pickle.dump(G, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580c36ed-e8a7-44be-8866-0b9ce7cc7b32",
   "metadata": {},
   "source": [
    "## Synonyms for each listed entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0721a5-374d-454b-9980-b3928e64d8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code is not pretty, but overall just get all the synonyms of all the mentioned entities\n",
    "syn_df = pd.concat([df[[\"Symbol A\", \"Synonym A\", \"Uniprot A\"]].rename(columns={\"Symbol A\": \"Symbol\",\n",
    "                                                                               \"Synonym A\": \"name\",\n",
    "                                                                               \"Uniprot A\": \"Id\"\n",
    "                                                                              }),\n",
    "                    df[[\"Symbol B\", \"Synonym B\", \"Uniprot B\"]].rename(columns={\"Symbol B\": \"Symbol\",\n",
    "                                                                               \"Synonym B\": \"name\",\n",
    "                                                                               \"Uniprot B\": \"Id\"\n",
    "                                                                              })],\n",
    "                   axis=0).drop_duplicates()\n",
    "\n",
    "syn_df[\"name\"] = syn_df.Symbol.str.cat(syn_df.name, sep=\"|\")\n",
    "syn_df = syn_df[syn_df[\"name\"] != \"-\"].copy()\n",
    "syn_df[\"name\"] = syn_df[\"name\"].str.split(\"|\")\n",
    "syn_df = syn_df.explode(\"name\").reset_index(drop=True)\n",
    "syn_df = syn_df[syn_df[\"name\"] != \"-\"]\n",
    "syn_df = syn_df.drop(columns=\"Symbol\").drop_duplicates().reset_index(drop=True)\n",
    "syn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2955e2ae-299d-4882-99a7-e43c26d97384",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"BIOGRID_nodes.pkl\", \"wb\") as p:\n",
    "    pickle.dump(syn_df, p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
